<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Visar Berisha, PhD</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Associate Professor at Arizona State University" />
    <meta name="keywords" content="Aural Analytics, asu, machine learning, AI, clinical AI, healthcare AI, digital health, diagnosis, voice biomarkers, speech biomarkers, speech analytics, speech AI, natural language processing, health, prognosis, tracking, neurological disease, speech processing, health, signal processing, pattern recognition, speech pathologies, dysarthria, arizona state university, tempe, arizona" />
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous">
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="site.css">
  </head>

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-49157441-2', 'auto');
    ga('send', 'pageview');
  </script>
  
  <body>
    <br>
    <div class="container">
      <nav class="navbar sticky-top navbar-expand-lg navbar-dark" style="background-color: #990033;">
        <a class="navbar-brand" href="index.html">Visar Berisha</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
          <div class="navbar-nav">
            <a class="nav-item nav-link" href="index.html">About Me</a>
            <a class="nav-item nav-link" href="research.html">Research</a>
            <a class="nav-item nav-link" href="pubs.html">Publications</a>
            <a class="nav-item nav-link" href="group.html">Group</a>
            <a class="nav-item nav-link" href="support.html">Support</a>
          </div>
        </div>
      </nav>
    </div>
    <div class="container">
      <div class="row">
        <div class="col-lg-12">

          <hr style = "clear:left"/>

<h4 class="my-3">Tracking Human Health Through Speech and Language</h4>
Neurological disorders or traumatic brain injury may disturb an individual’s speech and language abilities well before such changes are perceptually detectable. For example, Parkinson’s Disease can result in speaking rate changes, reduced intonation, imprecise articulation, etc.; Alzheimer’s Disease can result in longer pauses during speech, reduced vocabulary, reduced language complexity, etc. The goal of this project is to develop signal processing and machine learning technology to detect subtle speech and language changes and to use these algorithms in devices for early detection, real-time symptom tracking, and intervention monitoring. This work is funded by several projects from the NIH and the NSF.
<br><br>

<h5>Relevant Publications:</h5>
<ul>
<li> Stegmann, G., Hahn, S., Bhandari, S., Kawabata, K., Shefner, J., Duncan, C.J., Liss, J., Berisha, V. and Mueller, K., 2022. Automated semantic relevance as an indicator of cognitive decline: Out‐of‐sample validation on a large‐scale longitudinal dataset. Alzheimer's & Dementia: Diagnosis, Assessment & Disease Monitoring, 14(1).
<li> Stegmann, G.M., Hahn, S., Duncan, C.J., Rutkove, S.B., Liss, J., Shefner, J.M. and Berisha, V., 2021. Estimation of forced vital capacity using speech acoustics in patients with ALS. Amyotrophic Lateral Sclerosis and Frontotemporal Degeneration, 22(sup1).
<li>Stegmann, G., Hahn, S., Liss, J., Shefner, J., Rutkove, S., Shelton, K., Duncan, C.J. and Berisha, V., 2020. Early detection and tracking of bulbar changes in ALS via frequent and remote speech analysis. npj Digital Medicine, 3(1), pp.1-5.
<li>Stegmann, G., Hahn, S., Liss, J., Shefner, J., Rutkove, S.B., Kawabata, K., Bhandari, S., Shelton, K., Duncan, C.J. and Berisha, V., 2020. Repeatability of Commonly Used Speech and Language Features for Clinical Applications. Digital Biomarkers, 4(3), pp.109-122
<li>Mathad, V., Scherer, N., Chapman, K., Liss, J. and Berisha, V., 2021. A Deep Learning Algorithm for Objective Assessment of Hypernasality in Children with Cleft Palate. IEEE Transactions on Biomedical Engineering. Jan 2021.
<li>Schwedt, T., Peplinski, J., Berisha, V. (2019). Altered speech during migraine attacks: A prospective, longitudinal study of episodic migraine without aura. Cephalalgia.
<li>Rutkove, S., Qi, K., Shelton, K., Liss, J., Berisha, V., Shefner, J. 2019. ALS longitudinal studies with frequent data collection at home: study design and baseline data. Amyotrophic Lateral Sclerosis and Frontotemporal Degeneration.
<li>Berisha, V., Wang, S., LaCross, A., Liss, J., Garcia-Filion, P. 2017. Longitudinal changes in linguistic complexity among professional football players. Brain and language, 169, 57-63.
</ul>

<hr style = "clear:left"/>


<h4 class="my-3">Improving Robustness and Efficiency in Machine Learning: Theory and Algorithms</h4>
A fundamental problem in machine learning (ML) is developing models that generalize to real-world conditions after training. In practice, this problem is solved by using massive training data to train high-capacity models. We are interested in the scenario where labeled data is available, but costly (i.e. this is the case in most clinical applications). This project is focused on how we can exploit the structure of data (labeled and unlabeled) and active learning to efficiently develop robust models that generalize. This work is funded by several projects from the ONR and the NSF.

<br><br>
<h5>Relevant Publications:</h5>
<ul>
  <li>Li, W., Dasarathy, G., Ramamurthy, K.N. and Berisha, V., 2022. A label efficient two-sample test. Proceedings of UAI.
<li>Li, W., Dasarathy, G., Ramamurthy, K.N. and Berisha, V., 2020. Finding the Homology of Decision Boundaries with Active Learning. Proceedings of NeurIPS.
<li>Li, W., Dasarathy, G., & Berisha, V. 2020. Regularization via Structural Label Smoothing. Proceedings of AISTATS.
<li>Wisler, A., Berisha, V., Spanias, A., & Hero, A. O. 2018. Direct estimation of density functionals using a polynomial basis. IEEE Transactions on Signal Processing, 66(3), 558-572.
<li>Berisha, V., Wisler, A., Hero, A. O., & Spanias, A. 2016. Empirically estimable classification bounds based on a nonparametric divergence measure. IEEE Transactions on Signal Processing, 64(3), 580-591.
<li>Berisha, V., & Hero, A. O. 2015. Empirical non-parametric estimation of the Fisher Information. IEEE Signal Processing Letters, 22(7), 988-992.
</ul>


<hr style = "clear:left"/>


<h4 class="my-3">Speech/Audio Compression Based on Loudness Criteria</h4>
Based on several psychoacoustic principles, a number of different computational auditory models have been developed over the years to mimic aspects of the human auditory system. Embedding these models within existing audio compression algorithms (e.g. MP-3) has led to significant increases in coding efficiency. In this project, we consider an alternative psychoacoustic model based on loudness for inclusion in speech/audio codecs. Loudness is a subjective phenomenon which represents the magnitude of perceived intensity, i.e., it is a measure of the magnitude of neural activity that corresponds to the hearing sensations. When embedded in an existing compression algorithm, results reveal that the proposed system improves the quality of narrowband speech while performing at a lower bitrate. When compared to other wideband speech coding schemes, the proposed algorithms provide comparable speech quality at a lower bitrate.

<br><br>
<h5>Relevant Publications:</h5>
<ul>
<li> Krishnamoorthi, H., Spanias, A. and Berisha, V., 2009. A frequency/detector pruning approach for loudness estimation. IEEE Signal Processing Letters, 16(11), pp.997-1000.
<li> Berisha, V. and Spanias, A., 2007. Wideband speech recovery using psychoacoustic criteria. EURASIP Journal on Audio, Speech, and Music Processing, 2007, pp.1-18.
</ul>


    </div>
  </div>
</div>


  </body>
</html>
